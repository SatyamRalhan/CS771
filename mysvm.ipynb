{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cs771 import genSyntheticData as gsd\n",
    "from cs771 import plotData as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import time as tm\n",
    "import random\n",
    "\n",
    "# Dataset 1 - set of two oblique ellipsoids\n",
    "\n",
    "muPos = np.array( [-3,0] )\n",
    "muNeg = np.array( [3,3] )\n",
    "cov = np.array( [[16, -14] , [-14, 16]] )\n",
    "\n",
    "# Set n to be a large number to visualize the speed benefits of SGD/MB over GD\n",
    "d = 2 \n",
    "n = 6000\n",
    "\n",
    "XPos = gsd.genEllipticalData( d, n, muPos, cov )\n",
    "XNeg = gsd.genEllipticalData( d, n, muNeg, cov )\n",
    "yPos = np.ones( (n,) )\n",
    "yNeg = -np.ones( (n,) )\n",
    "X = np.vstack( (XPos, XNeg) )\n",
    "y = np.concatenate( (yPos, yNeg) )\n",
    "\n",
    "# Dataset 2 - set of two circles with a couple of outliers\n",
    "# Comment this section out in order to try dataset 1\n",
    "\n",
    "muPos1 = np.array( [-5,5] )\n",
    "muPos2 = np.array( [1,-5] )\n",
    "muNeg = np.array( [-5,-5] )\n",
    "r = 3\n",
    "\n",
    "tmp1 = gsd.genSphericalData( d, n, muPos1, r)\n",
    "tmp2 = gsd.genSphericalData( d, n//30, muPos2, r//2 )\n",
    "XPos = np.vstack( (tmp1, tmp2) )\n",
    "XNeg = gsd.genSphericalData( d, n, muNeg, r )\n",
    "yPos = np.ones( (n + n//30,) )\n",
    "yNeg = -np.ones( (n,) )\n",
    "X = np.vstack( (XPos, XNeg) )\n",
    "y = np.concatenate( (yPos, yNeg) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the CSVM gradient\n",
    "# def getCSVMGrad( theta ):\n",
    "#     w = theta[0:-1]\n",
    "#     b = theta[-1]\n",
    "#     discriminant = np.multiply( (X.dot( w ) + b), y )\n",
    "#     g = np.zeros( (y.size,) )\n",
    "#     g[discriminant < 1] = -1\n",
    "#     delb = C * g.dot( y )\n",
    "#     delw = w + C * (X.T * g).dot( y )\n",
    "#     return np.append( delw, delb )\n",
    "\n",
    "# Get a stochastic gradient for the CSVM objective\n",
    "# Choose a random data point per iteration\n",
    "def getCSVMSGrad( theta ):\n",
    "    w = theta[0:-1]\n",
    "    b = theta[-1]\n",
    "    n = y.size\n",
    "    i = random.randint( 0, n-1 )\n",
    "    x = X[i,:]\n",
    "    discriminant = (x.dot( w )) * y[i]\n",
    "    g = 0\n",
    "    if discriminant < 1:\n",
    "        g = -1\n",
    "#     delb = C * g * y[i]\n",
    "    delw = w + 2 * C * n * (x * g) * y[i] * (1-discriminant)\n",
    "    return np.append( delw, b )\n",
    "\n",
    "# Get a mini-batch stochastic gradient for CSVM\n",
    "# Choose a random set of B samples per iteration\n",
    "# def getCSVMMBGrad( theta ):\n",
    "#     w = theta[0:-1]\n",
    "#     b = theta[-1]\n",
    "#     n = y.size\n",
    "#     if B <= n:\n",
    "#         samples = random.sample( range(0, n), B )\n",
    "#         X_ = X[samples,:]\n",
    "#         y_ = y[samples]\n",
    "#     else:\n",
    "#         X_ = X\n",
    "#         y_ = y\n",
    "#     discriminant = np.multiply( (X_.dot( w ) + b), y_ )\n",
    "#     g = np.zeros( (B,) )\n",
    "#     g[discriminant < 1] = -1\n",
    "#     delb = C * g.dot( y_ )\n",
    "#     delw = w + C * n/B * (X_.T * g).dot( y_ )\n",
    "#     return np.append( delw, delb )\n",
    "\n",
    "# Quite standard for strongly convex but non-smooth objectives like CSVM\n",
    "def getStepLength( grad, t ):\n",
    "    return eta/(t+1)\n",
    "\n",
    "# Get the CSVM objective value in order to plot convergence curves\n",
    "def getCSVMObjVal( theta ):\n",
    "    w = theta[0:-1]\n",
    "    b = theta[-1]\n",
    "#     hingeLoss = np.maximum( 1 - np.multiply( (X.dot( w ) + b), y ), 0 )\n",
    "    hingeLoss = np.maximum( 1 - np.multiply( (X.dot( w )), y ), 0 )\n",
    "    return 0.5 * w.dot( w ) + C * np.sum( hingeLoss )\n",
    "\n",
    "# Given a gradient oracle, a step length oracle, an initialization,\n",
    "# perform GD for a specified number of steps (horizon)\n",
    "# An \"oracle\" is a fancy name for a function that does a certain job perfectly\n",
    "def doGD( gradFunc, stepFunc, init, horizon = 10 ):\n",
    "    objValSeries = np.zeros( (horizon,) )\n",
    "    timeSeries = np.zeros( (horizon,) )\n",
    "    totTime = 0\n",
    "    theta = init\n",
    "    cumulative = init\n",
    "    for t in range( horizon ):\n",
    "        tic = tm.perf_counter()\n",
    "        delta = gradFunc( theta )\n",
    "        theta = theta - stepFunc( delta, t+1 ) * delta\n",
    "        cumulative = cumulative + theta\n",
    "        toc = tm.perf_counter()\n",
    "        totTime = totTime + (toc - tic)\n",
    "        objValSeries[t] = getCSVMObjVal( cumulative/(t+2) )\n",
    "        timeSeries[t] = totTime\n",
    "    return (cumulative/(horizon+1), objValSeries, timeSeries)\n",
    "\n",
    "def mySVM( X ):\n",
    "    return X.dot(w) + b\n",
    "\n",
    "# CSVM problems get progressively more and more difficult as C goes up\n",
    "# All solvers, GD/SGD/sklearn will struggle with large values of C\n",
    "# C = 1\n",
    "# eta = 2\n",
    "# (theta, obj, time) = doGD( getCSVMGrad, getStepLength, np.zeros( (d+1,) ), horizon = 500 )\n",
    "\n",
    "# Experiment to observe that SGD and MB offer much faster convergence than GD, especially when n is large\n",
    "# Also, plot just the SGD and MB curves repeatedly to observe that the SGD curve jitters from execution\n",
    "# to execution (an indication of variance) whereas the MB curve remains relatively stable across executions\n",
    "C = 1\n",
    "eta = 2\n",
    "B = 10\n",
    "(theta_SGD, obj_SGD, time_SGD) = doGD( getCSVMSGrad, getStepLength, np.zeros( (d+1,) ), horizon = 500 )\n",
    "# (theta_MB, obj_MB, time_MB) = doGD( getCSVMMBGrad, getStepLength, np.zeros( (d+1,) ), horizon = 500 )\n",
    "\n",
    "# w = theta[0:-1]\n",
    "# b = theta[-1]\n",
    "\n",
    "# fig = pd.getFigure( 7, 7 )\n",
    "# pd.shade2D( mySVM, fig, mode = 'batch', xlim = 10, ylim = 10 )\n",
    "# pd.plot2D( XPos, fig, color = 'r', marker = '+' )\n",
    "# pd.plot2D( XNeg, fig, color = 'g', marker = 'o' )\n",
    "# plt.show()\n",
    "\n",
    "w = theta_SGD[0:-1]\n",
    "b = theta_SGD[-1]\n",
    "\n",
    "fig2 = pd.getFigure( 7, 7 )\n",
    "pd.shade2D( mySVM, fig, mode = 'batch', xlim = 10, ylim = 10 )\n",
    "pd.plot2D( XPos, fig, color = 'r', marker = '+' )\n",
    "pd.plot2D( XNeg, fig, color = 'g', marker = 'o' )\n",
    "plt.show()\n",
    "\n",
    "# w = theta_MB[0:-1]\n",
    "# b = theta_MB[-1]\n",
    "\n",
    "# fig3 = pd.getFigure( 7, 7 )\n",
    "# pd.shade2D( mySVM, fig, mode = 'batch', xlim = 10, ylim = 10 )\n",
    "# pd.plot2D( XPos, fig, color = 'r', marker = '+' )\n",
    "# pd.plot2D( XNeg, fig, color = 'g', marker = 'o' )\n",
    "# plt.show()\n",
    "\n",
    "# fig4 = pd.getFigure( 7, 7 )\n",
    "# plt.figure( fig4.number )\n",
    "# plt.plot( time, obj, color = 'k', linestyle = '--', label = \"GD\" )\n",
    "# plt.plot( time_SGD, obj_SGD, color = 'r', linestyle = '-', label = \"SGD\" )\n",
    "# plt.plot( time_MB, obj_MB, color = 'b', linestyle = ':', label = \"MB\" )\n",
    "# plt.xlabel( \"Elapsed time (sec)\" )\n",
    "# plt.ylabel( \"C-SVM Objective value\" )\n",
    "# plt.legend()\n",
    "# plt.ylim( 0, 10000000 )\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
